#!/usr/bin/env python3
"""
Ð¡ÐºÑ€Ð¸Ð¿Ñ‚ Ð´Ð»Ñ Ð¸Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ñ ÑƒÐ½Ð¸ÐºÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ð´Ð¾Ð¼ÐµÐ½Ð¾Ð² Ð¸Ð· Ñ„Ð°Ð¹Ð»Ð° nagul.txt
Ð¸ Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ñ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹ Ð¿Ñ€Ð¾Ð³Ñ€ÐµÐ²Ð° Ð¿Ñ€Ð¾Ñ„Ð¸Ð»ÐµÐ¹.
"""

import re
import json
from urllib.parse import urlparse
from pathlib import Path


def extract_domains_from_file(file_path: str) -> set:
    """Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÑ‚ ÑƒÐ½Ð¸ÐºÐ°Ð»ÑŒÐ½Ñ‹Ðµ Ð´Ð¾Ð¼ÐµÐ½Ñ‹ Ð¸Ð· Ñ„Ð°Ð¹Ð»Ð° Ñ ÑÑÑ‹Ð»ÐºÐ°Ð¼Ð¸."""
    domains = set()

    print(f"Ð§Ð¸Ñ‚Ð°ÐµÐ¼ Ñ„Ð°Ð¹Ð»: {file_path}")

    with open(file_path, 'r', encoding='utf-8') as f:
        for line_num, line in enumerate(f, 1):
            # ÐÐ°Ñ…Ð¾Ð´Ð¸Ð¼ Ð²ÑÐµ URL Ð² ÑÑ‚Ñ€Ð¾ÐºÐµ
            urls = re.findall(r'https?://[^\s,]+', line.strip())

            for url in urls:
                try:
                    # ÐŸÐ°Ñ€ÑÐ¸Ð¼ URL Ð¸ Ð¸Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼ Ð´Ð¾Ð¼ÐµÐ½
                    parsed = urlparse(url)
                    domain = parsed.netloc.lower()

                    # Ð£Ð±Ð¸Ñ€Ð°ÐµÐ¼ www. ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ
                    if domain.startswith('www.'):
                        domain = domain[4:]

                    # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ ÐµÑÐ»Ð¸ Ð´Ð¾Ð¼ÐµÐ½ Ð½Ðµ Ð¿ÑƒÑÑ‚Ð¾Ð¹
                    if domain:
                        domains.add(domain)

                except Exception as e:
                    print(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³Ð° URL '{url}' Ð² ÑÑ‚Ñ€Ð¾ÐºÐµ {line_num}: {e}")
                    continue

            # ÐŸÐ¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÐ¼ Ð¿Ñ€Ð¾Ð³Ñ€ÐµÑÑ ÐºÐ°Ð¶Ð´Ñ‹Ðµ 10000 ÑÑ‚Ñ€Ð¾Ðº
            if line_num % 10000 == 0:
                print(f"ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð¾ {line_num} ÑÑ‚Ñ€Ð¾Ðº, Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ {len(domains)} ÑƒÐ½Ð¸ÐºÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ð´Ð¾Ð¼ÐµÐ½Ð¾Ð²")

    return domains


def categorize_domains(domains: set) -> dict:
    """ÐšÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ð·Ð¸Ñ€ÑƒÐµÑ‚ Ð´Ð¾Ð¼ÐµÐ½Ñ‹ Ð¿Ð¾ Ñ‚Ð¸Ð¿Ð°Ð¼ ÑÐ°Ð¹Ñ‚Ð¾Ð²."""
    categories = {
        'search_engines': [],
        'social_media': [],
        'news_media': [],
        'e_commerce': [],
        'educational': [],
        'entertainment': [],
        'technology': [],
        'food_cooking': [],
        'travel': [],
        'finance': [],
        'health': [],
        'automotive': [],
        'real_estate': [],
        'other': []
    }

    # Ð¡Ð»Ð¾Ð²Ð°Ñ€Ð¸ ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ñ… ÑÐ»Ð¾Ð² Ð´Ð»Ñ ÐºÐ°Ð¶Ð´Ð¾Ð¹ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ð¸
    keywords = {
        'search_engines': ['google', 'yandex', 'bing', 'yahoo', 'rambler', 'mail.ru'],
        'social_media': ['vk.com', 'ok.ru', 'facebook', 'instagram', 'twitter', 'telegram', 'youtube', 'tiktok'],
        'news_media': ['rbc.ru', 'ria.ru', 'tass.ru', 'lenta.ru', 'gazeta.ru', 'kommersant.ru', 'vedomosti.ru'],
        'e_commerce': ['ozon.ru', 'wildberries.ru', 'market.yandex.ru', 'avito.ru', 'aliexpress', 'amazon'],
        'educational': ['wikipedia', 'wikihow', 'edu', 'coursera', 'edx'],
        'entertainment': ['kinopoisk.ru', 'ivi.ru', 'netflix', 'spotify', 'music.yandex.ru'],
        'technology': ['habr.com', 'github.com', 'stackoverflow', 'techcrunch'],
        'food_cooking': ['edimdoma.ru', 'povar.ru', 'gastronom.ru', 'food.ru'],
        'travel': ['booking.com', 'tripadvisor', 'aviasales.ru', 'tutu.ru'],
        'finance': ['sberbank.ru', 'tinkoff.ru', 'vtb.ru', 'alfabank.ru'],
        'health': ['who.int', 'mayo', 'webmd', 'zdorovie'],
        'automotive': ['auto.ru', 'drom.ru', 'cars.com'],
        'real_estate': ['cian.ru', 'domclick.ru', 'zillow']
    }

    for domain in domains:
        categorized = False

        for category, category_keywords in keywords.items():
            if any(keyword in domain.lower() for keyword in category_keywords):
                categories[category].append(domain)
                categorized = True
                break

        if not categorized:
            categories['other'].append(domain)

    # Ð¡Ð¾Ñ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð´Ð¾Ð¼ÐµÐ½Ñ‹ Ð² ÐºÐ°Ð¶Ð´Ð¾Ð¹ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ð¸
    for category in categories:
        categories[category].sort()

    return categories


def save_domains_to_files(domains: set, categorized_domains: dict):
    """Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÑ‚ Ð´Ð¾Ð¼ÐµÐ½Ñ‹ Ð² Ñ€Ð°Ð·Ð»Ð¸Ñ‡Ð½Ñ‹Ðµ Ñ„Ð°Ð¹Ð»Ñ‹."""

    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð¿Ð°Ð¿ÐºÑƒ Ð´Ð»Ñ Ð´Ð°Ð½Ð½Ñ‹Ñ… ÐµÑÐ»Ð¸ ÐµÑ‘ Ð½ÐµÑ‚
    data_dir = Path("data/warmup_sites")
    data_dir.mkdir(parents=True, exist_ok=True)

    # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð²ÑÐµ ÑƒÐ½Ð¸ÐºÐ°Ð»ÑŒÐ½Ñ‹Ðµ Ð´Ð¾Ð¼ÐµÐ½Ñ‹
    all_domains_file = data_dir / "all_domains.txt"
    with open(all_domains_file, 'w', encoding='utf-8') as f:
        for domain in sorted(domains):
            f.write(f"https://{domain}\n")

    print(f"Ð’ÑÐµ Ð´Ð¾Ð¼ÐµÐ½Ñ‹ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ñ‹ Ð²: {all_domains_file}")
    print(f"Ð’ÑÐµÐ³Ð¾ ÑƒÐ½Ð¸ÐºÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ð´Ð¾Ð¼ÐµÐ½Ð¾Ð²: {len(domains)}")

    # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð¾Ð¼ÐµÐ½Ñ‹
    categories_file = data_dir / "domains_by_category.json"
    with open(categories_file, 'w', encoding='utf-8') as f:
        json.dump(categorized_domains, f, ensure_ascii=False, indent=2)

    # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²ÐµÐ½Ð½Ñ‹Ðµ Ð´Ð¾Ð¼ÐµÐ½Ñ‹ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð³Ñ€ÐµÐ²Ð°
    quality_domains = []
    priority_categories = ['search_engines', 'social_media', 'news_media', 'e_commerce',
                          'educational', 'entertainment', 'technology']

    for category in priority_categories:
        quality_domains.extend(categorized_domains[category])

    # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð½ÐµÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ð¸Ð· Ð´Ñ€ÑƒÐ³Ð¸Ñ… ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ð¹ (Ð½Ðµ Ð±Ð¾Ð»ÐµÐµ 50 Ð´Ð¾Ð¼ÐµÐ½Ð¾Ð² Ð¸Ð· ÐºÐ°Ð¶Ð´Ð¾Ð¹)
    for category in ['food_cooking', 'travel', 'finance', 'health']:
        quality_domains.extend(categorized_domains[category][:50])

    # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ 100 ÑÐ»ÑƒÑ‡Ð°Ð¹Ð½Ñ‹Ñ… Ð´Ð¾Ð¼ÐµÐ½Ð¾Ð² Ð¸Ð· ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ð¸ 'other'
    import random
    other_domains = categorized_domains['other']
    if len(other_domains) > 100:
        quality_domains.extend(random.sample(other_domains, 100))
    else:
        quality_domains.extend(other_domains)

    # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²ÐµÐ½Ð½Ñ‹Ðµ Ð´Ð¾Ð¼ÐµÐ½Ñ‹ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð³Ñ€ÐµÐ²Ð°
    warmup_domains_file = data_dir / "warmup_domains.txt"
    with open(warmup_domains_file, 'w', encoding='utf-8') as f:
        for domain in sorted(set(quality_domains)):
            f.write(f"https://{domain}\n")

    print(f"Ð”Ð¾Ð¼ÐµÐ½Ñ‹ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð³Ñ€ÐµÐ²Ð° ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ñ‹ Ð²: {warmup_domains_file}")
    print(f"ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð´Ð¾Ð¼ÐµÐ½Ð¾Ð² Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð³Ñ€ÐµÐ²Ð°: {len(set(quality_domains))}")

    # Ð’Ñ‹Ð²Ð¾Ð´Ð¸Ð¼ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ Ð¿Ð¾ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸ÑÐ¼
    print("\n=== Ð¡Ð¢ÐÐ¢Ð˜Ð¡Ð¢Ð˜ÐšÐ ÐŸÐž ÐšÐÐ¢Ð•Ð“ÐžÐ Ð˜Ð¯Ðœ ===")
    for category, domains_list in categorized_domains.items():
        if domains_list:
            print(f"{category}: {len(domains_list)} Ð´Ð¾Ð¼ÐµÐ½Ð¾Ð²")

    return warmup_domains_file


def main():
    """Ð“Ð»Ð°Ð²Ð½Ð°Ñ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ñ ÑÐºÑ€Ð¸Ð¿Ñ‚Ð°."""

    print("ðŸ” Ð˜Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ðµ Ð´Ð¾Ð¼ÐµÐ½Ð¾Ð² Ð¸Ð· Ñ„Ð°Ð¹Ð»Ð° nagul.txt")
    print("=" * 50)

    # ÐŸÑƒÑ‚ÑŒ Ðº Ñ„Ð°Ð¹Ð»Ñƒ nagul.txt
    nagul_file = Path("nagul.txt")

    if not nagul_file.exists():
        print(f"âŒ Ð¤Ð°Ð¹Ð» {nagul_file} Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½!")
        return

    # Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼ Ð´Ð¾Ð¼ÐµÐ½Ñ‹
    domains = extract_domains_from_file(nagul_file)

    print(f"\nâœ… Ð˜Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ðµ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¾!")
    print(f"ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ ÑƒÐ½Ð¸ÐºÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ð´Ð¾Ð¼ÐµÐ½Ð¾Ð²: {len(domains)}")

    # ÐšÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ Ð´Ð¾Ð¼ÐµÐ½Ñ‹
    print("\nðŸ“Š ÐšÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð´Ð¾Ð¼ÐµÐ½Ð¾Ð²...")
    categorized_domains = categorize_domains(domains)

    # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹
    print("\nðŸ’¾ Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²...")
    warmup_file = save_domains_to_files(domains, categorized_domains)

    print(f"\nðŸŽ‰ ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð°!")
    print(f"Ð¤Ð°Ð¹Ð» Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð³Ñ€ÐµÐ²Ð°: {warmup_file}")

    # ÐŸÐ¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÐ¼ Ð¿Ñ€Ð¸Ð¼ÐµÑ€Ñ‹ Ð´Ð¾Ð¼ÐµÐ½Ð¾Ð²
    print(f"\nðŸ“‹ ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹ Ð¸Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð½Ñ‹Ñ… Ð´Ð¾Ð¼ÐµÐ½Ð¾Ð²:")
    sample_domains = sorted(list(domains))[:20]
    for i, domain in enumerate(sample_domains, 1):
        print(f"{i:2d}. {domain}")

    if len(domains) > 20:
        print(f"    ... Ð¸ ÐµÑ‰Ðµ {len(domains) - 20} Ð´Ð¾Ð¼ÐµÐ½Ð¾Ð²")


if __name__ == "__main__":
    main()